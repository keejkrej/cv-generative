# Computer Vision Generative Models

A comprehensive PyTorch implementation of state-of-the-art generative models for computer vision, covering image generation, video generation, and 3D content creation.

## Overview

This repository implements the most important deep learning algorithms for generative computer vision with a focus on clarity, modularity, and practical usability. Each model includes detailed documentation explaining the architecture, training strategies, and performance characteristics.

## Implemented Models

### ðŸŽ¨ Image Generation
- **Stable Diffusion (SDXL & SD3)** - Latent diffusion models with advanced architectures
- **FLUX.1** - 12B parameter state-of-the-art diffusion transformer
- **DALL-E 3** - OpenAI's model with superior prompt understanding
- **Imagen 3** - Google's cascaded diffusion architecture

### ðŸŽ¬ Video Generation
- **OpenAI Sora** - Diffusion transformer for long-form video generation
- **Runway Gen-3 Alpha** - Professional video generation with fine control
- **Luma AI Dream Machine** - Fast and consistent video generation
- **Stable Video Diffusion** - Open-source video generation model

### ðŸŽ® 3D Generation
- **3D Gaussian Splatting** - Real-time neural rendering
- **Neural Radiance Fields (NeRF)** - Implicit 3D scene representation
- **Point-E & Shap-E** - OpenAI's 3D generation models
- **GET3D** - NVIDIA's textured mesh generation

## Installation

```bash
git clone https://github.com/yourusername/cv-generative.git
cd cv-generative
pip install -r requirements.txt
```

## Quick Start

### Image Generation
```python
from models.image_generation.stable_diffusion import SDXL

# Initialize model
model = SDXL.from_pretrained("stabilityai/stable-diffusion-xl-base-1.0")

# Generate image
image = model.generate(
    prompt="A futuristic cityscape at sunset",
    num_inference_steps=50,
    guidance_scale=7.5
)
```

### Video Generation
```python
from models.video_generation.svd import StableVideoDiffusion

# Initialize model
model = StableVideoDiffusion.from_pretrained("stabilityai/stable-video-diffusion")

# Generate video from image
video = model.generate(
    image=input_image,
    num_frames=25,
    fps=7
)
```

### 3D Generation
```python
from models.3d_generation.gaussian_splatting import GaussianSplatting

# Initialize model
model = GaussianSplatting()

# Reconstruct 3D scene from images
scene = model.reconstruct(
    images=multi_view_images,
    camera_poses=poses
)
```

## Project Structure

```
cv-generative/
â”œâ”€â”€ models/              # Model implementations
â”œâ”€â”€ utils/              # Shared utilities
â”œâ”€â”€ train/              # Training scripts
â”œâ”€â”€ inference/          # Inference scripts
â”œâ”€â”€ evaluate/           # Evaluation metrics
â””â”€â”€ examples/           # Example notebooks
```

## Requirements

- Python 3.8+
- PyTorch 2.0+
- CUDA 11.8+ (for GPU acceleration)
- 16GB+ GPU memory (recommended)

## Documentation

Each model directory contains a detailed README with:
- Architecture explanations
- Training procedures
- Performance benchmarks
- Usage examples
- Implementation notes

## Contributing

Contributions are welcome! Please read our contributing guidelines before submitting PRs.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Citation

If you use this code in your research, please cite:
```bibtex
@software{cv-generative,
  title = {Computer Vision Generative Models},
  year = {2024},
  url = {https://github.com/yourusername/cv-generative}
}
```

## Acknowledgments

This implementation draws inspiration from the original papers and official implementations of each model. See individual model READMEs for specific citations.